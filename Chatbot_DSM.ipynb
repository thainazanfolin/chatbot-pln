{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2DcvrDYzHi0blUjGiX+u2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thainazanfolin/chatbot-pln/blob/main/Chatbot_DSM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CHATBOT | Curso de Desenvolvimento de Software Multiplataforma <br>**\n",
        "\n",
        "Objetivo: trazer as principais informações sobre o curso de Desenvolvimento de Software Multiplataforma da FATEC Araras a partir da pergunta do usuário. ]\n",
        "\n",
        "Passos a serem desenvolvidos:\n",
        "* Instalação e importação de bibliotecas\n",
        "* Extração de Dados do txt (github)\n",
        "* Preprocessamento: separação por sentenças, tokenização e retirada de stopwors\n",
        "* Cálculo de similaridade para encontrar a melhor respostar (answer)\n",
        "* Desenvolvimento do Chatbot\n",
        "* Criação da Interface Gráfica\n",
        "* Testes e Validação"
      ],
      "metadata": {
        "id": "HCeRdx1HdIRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import string\n",
        "import requests\n",
        "\n",
        "# Baixar os recursos necessários\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Carregar o modelo de linguagem em português do spaCy\n",
        "nlp = spacy.load(\"pt_core_news_md\")\n",
        "\n",
        "# Modelo de Q&A da biblioteca Transformers\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
        "\n",
        "#------------- FUNÇÕES ------------#\n",
        "\n",
        "# mensagem de boas-vindas\n",
        "def welcome_message(user_text):\n",
        "    greetings = [\"hello\", \"hi\", \"hey\", \"greetings\", \"olá\", \"oi\", \"oie\"]\n",
        "    for word in word_tokenize(user_text.lower()):\n",
        "        if word in greetings:\n",
        "            return \"Olá! Como posso te ajudar hoje?\"\n",
        "    return None\n",
        "\n",
        "# preprocessamento para remover pontuação, stop words e tokenizar\n",
        "def preprocessamento(texto):\n",
        "    stop_words = set(stopwords.words('portuguese'))\n",
        "    texto = texto.lower()  # converte o texto para minúsculas\n",
        "    texto = texto.translate(str.maketrans('', '', string.punctuation))  # remove pontuação\n",
        "    doc = nlp(texto)  # processa o texto com spaCy para lematização\n",
        "    tokens_filtrados = [token.lemma_ for token in doc if token.text not in stop_words]  # remove stop words e aplica lematização\n",
        "    return \" \".join(tokens_filtrados)  # retorna os tokens filtrados como uma string\n",
        "\n",
        "# carregar base de conhecimento\n",
        "def carregar_conteudo():\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # verificar se a requisição foi bem-sucedida\n",
        "    if response.status_code == 200:\n",
        "        return response.text\n",
        "    else:\n",
        "        return f\"Erro ao acessar o arquivo: {response.status_code}\"\n",
        "\n",
        "# calcular a similaridade usando TF-IDF e cosine similarity\n",
        "def calcular_similaridade(pergunta, sentencas):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "\n",
        "    # criar uma lista de strings para TF-IDF a partir da pergunta e das sentenças preprocessadas\n",
        "    docs = sentencas + [pergunta]  # adiciona a pergunta ao final da lista de sentenças\n",
        "    tfidf_matrix = vectorizer.fit_transform(docs)\n",
        "    similaridades = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1]).flatten()  # calcula a similaridade entre a pergunta e as sentenças\n",
        "    return similaridades\n",
        "\n",
        "# encontrar as melhores respostas com base em um limiar de similaridade\n",
        "def answer(user_text, threshold=0.1):\n",
        "    user_text = preprocessamento(user_text)  # preprocessar a pergunta do usuário\n",
        "    similaridades = calcular_similaridade(user_text, sentencas_preprocessadas)  # calcular a similaridade com as sentenças preprocessadas\n",
        "\n",
        "    # encontrar todas as sentenças com similaridade acima do limiar\n",
        "    respostas_relevantes = [f\"* {sentencas_original[i]}\" for i, similaridade in enumerate(similaridades) if similaridade >= threshold]\n",
        "\n",
        "    # se nenhuma sentença for relevante, retornar uma mensagem padrão\n",
        "    if not respostas_relevantes:\n",
        "        return \"Desculpe, não consegui encontrar uma resposta relevante.\"\n",
        "\n",
        "    # else, retornar todas as sentenças relevantes, cada uma em uma nova linha\n",
        "    return \"\\n\".join(respostas_relevantes)\n",
        "\n",
        "#-------- BUSCANDO O ARQUIVO --------------#\n",
        "\n",
        "# URL do arquivo raw no GitHub\n",
        "url = 'https://raw.githubusercontent.com/thainazanfolin/chatbot-pln/refs/heads/main/curso-desenvolvimento-software.txt'\n",
        "\n",
        "# baixar o conteúdo do arquivo .txt usando a def criada\n",
        "texto_fatec = carregar_conteudo()  # carregar o conteúdo na variável que vamos utilizar com o texto sobre o curso\n",
        "\n",
        "#------- PREPROCESSAMENTO ------------#\n",
        "\n",
        "# melhorar a segmentação de sentenças com o sent_tokenize do NLTK\n",
        "sentencas_original = sent_tokenize(texto_fatec)  # dividir em sentenças com NLTK para melhor segmentação\n",
        "sentencas_preprocessadas = [preprocessamento(sentenca) for sentenca in sentencas_original]  # preprocessar cada sentença\n",
        "\n",
        "#---------- CHATBOT -----------#\n",
        "\n",
        "# implementando o loop de interação do chatbot\n",
        "cont = True\n",
        "print('Olá! Eu sou um chatbot e vou responder suas perguntas sobre o curso de Desenvolvimento de Software Multiplataforma da FATEC Araras. Escreva SAIR quando quiser encerrar nossa conversa!')\n",
        "\n",
        "while cont:\n",
        "    user_text = input()  # coletar a entrada do usuário\n",
        "\n",
        "    if user_text.lower() != 'sair':\n",
        "        # se o texto contém uma saudação (ver função)\n",
        "        if welcome_message(user_text) is not None:\n",
        "            print('Chatbot: ' + welcome_message(user_text))\n",
        "        else:\n",
        "            print('Chatbot: \\n' + answer(user_text))  # usar a função answer() para responder\n",
        "    else:\n",
        "        cont = False\n",
        "        print('Chatbot: Tchau! Até a próxima!')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "_4-cSKd0dJvA",
        "outputId": "eb8c5982-d360-4ba6-88df-b5ec3c947668"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Olá! Eu sou um chatbot e vou responder suas perguntas sobre o curso de Desenvolvimento de Software Multiplataforma da FATEC Araras. Escreva SAIR quando quiser encerrar nossa conversa!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-623fab010b84>\u001b[0m in \u001b[0;36m<cell line: 95>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mcont\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0muser_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# coletar a entrada do usuário\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'sair'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}